#!/usr/bin/env python3
"""
çŸ¥è¯†åº“ç³»ç»Ÿæ¼”ç¤ºè„šæœ¬
å±•ç¤ºåµŒå…¥æ¨¡å‹å’Œå‘é‡æ£€ç´¢çš„æ ¸å¿ƒåŠŸèƒ½
"""

import numpy as np
from embedding_utils import TextEmbedder
from vector_store import KnowledgeBase

def main():
    print("ğŸ¤– æ™ºèƒ½çŸ¥è¯†åº“ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–çŸ¥è¯†åº“
    print("æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“å’ŒåµŒå…¥æ¨¡å‹...")
    kb = KnowledgeBase()
    
    # ç¤ºä¾‹æ–‡æ¡£æ•°æ®
    documents = [
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ï¼Œä¸“æ³¨äºç®—æ³•å’Œç»Ÿè®¡æ¨¡å‹",
        "æ·±åº¦å­¦ä¹ åŸºäºç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ æ•°æ®çš„å±‚æ¬¡ç‰¹å¾",
        "è‡ªç„¶è¯­è¨€å¤„ç†ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€",
        "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿç†è§£å’Œåˆ†æè§†è§‰ä¿¡æ¯",
        "å¼ºåŒ–å­¦ä¹ é€šè¿‡è¯•é”™å­¦ä¹ æœ€ä¼˜å†³ç­–ç­–ç•¥",
        "Transformeræ¶æ„åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­å–å¾—äº†çªç ´æ€§è¿›å±•",
        "å·ç§¯ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²",
        "BERTæ¨¡å‹é€šè¿‡åŒå‘ç¼–ç å™¨å®ç°æ›´å¥½çš„è¯­è¨€ç†è§£"
    ]
    
    # æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
    print(f"æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“...")
    kb.add_documents(documents)
    
    print("\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:")
    stats = kb.vector_store.get_stats()
    print(f"  æ–‡æ¡£æ•°é‡: {stats['total_documents']}")
    print(f"  å‘é‡ç»´åº¦: {stats['embedding_dim']}")
    print(f"  ç´¢å¼•å¤§å°: {stats['index_size']}")
    
    # æµ‹è¯•æœç´¢æŸ¥è¯¢
    test_queries = [
        "äººå·¥æ™ºèƒ½çš„ç®—æ³•",
        "ç¥ç»ç½‘ç»œåº”ç”¨",
        "è¯­è¨€å¤„ç†æŠ€æœ¯",
        "å›¾åƒè¯†åˆ«æ–¹æ³•"
    ]
    
    print("\nğŸ” è¯­ä¹‰æœç´¢æµ‹è¯•:")
    print("=" * 50)
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: '{query}'")
        results = kb.search(query, top_k=2, similarity_threshold=0.5)
        
        if results:
            for i, result in enumerate(results, 1):
                print(f"  {i}. ç›¸ä¼¼åº¦: {result['similarity']:.3f}")
                print(f"     å†…å®¹: {result['text']}")
        else:
            print("  æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
    
    # æ¼”ç¤ºå‘é‡ç›¸ä¼¼åº¦è®¡ç®—
    print("\nğŸ“ å‘é‡ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º:")
    print("=" * 50)
    
    # è·å–ä¸€äº›æ–‡æ¡£çš„åµŒå…¥å‘é‡
    text1 = "æœºå™¨å­¦ä¹ ç®—æ³•"
    text2 = "æ·±åº¦å­¦ä¹ æ¨¡å‹" 
    text3 = "è®¡ç®—æœºè§†è§‰æŠ€æœ¯"
    
    embedder = TextEmbedder()
    vec1 = embedder.embed_text(text1)
    vec2 = embedder.embed_text(text2)
    vec3 = embedder.embed_text(text3)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    sim12 = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    sim13 = np.dot(vec1, vec3) / (np.linalg.norm(vec1) * np.linalg.norm(vec3))
    
    print(f"æ–‡æœ¬1: '{text1}'")
    print(f"æ–‡æœ¬2: '{text2}'")
    print(f"æ–‡æœ¬3: '{text3}'")
    print(f"\nç›¸ä¼¼åº¦æ¯”è¾ƒ:")
    print(f"  æ–‡æœ¬1 vs æ–‡æœ¬2: {sim12:.3f} (è¯­ä¹‰æ›´ç›¸è¿‘)")
    print(f"  æ–‡æœ¬1 vs æ–‡æœ¬3: {sim13:.3f}")
    
    # ä¿å­˜çŸ¥è¯†åº“æ¼”ç¤º
    print("\nğŸ’¾ çŸ¥è¯†åº“æŒä¹…åŒ–æ¼”ç¤º:")
    save_path = "demo_knowledge_base"
    kb.save(save_path)
    print(f"çŸ¥è¯†åº“å·²ä¿å­˜åˆ°: {save_path}")
    
    # åŠ è½½çŸ¥è¯†åº“æ¼”ç¤º
    kb_new = KnowledgeBase()
    kb_new.load(save_path)
    print(f"çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(kb_new.vector_store.texts)} ä¸ªæ–‡æ¡£")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. è¿è¡Œ 'streamlit run app.py' å¯åŠ¨Webç•Œé¢")
    print("2. ç¼–è¾‘ demo.py æ·»åŠ è‡ªå·±çš„æ–‡æ¡£æ•°æ®")
    print("3. å°è¯•ä¸åŒçš„æŸ¥è¯¢å’Œç›¸ä¼¼åº¦é˜ˆå€¼")

if __name__ == "__main__":
    main()